{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c57afb-d0aa-4e1a-b5dc-a5f996771c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "import openai\n",
    "openai.api_key = open('./openai_aip_key.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815e9054-98f4-4188-aeb5-b75a32240dd9",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b4b0e4-bdfb-4e92-ace6-88dad0a6f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapper = pd.read_csv('category.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766faf0-4197-46dc-9df6-1e52b59c60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wolt_reviews.csv')\n",
    "\n",
    "df = df[['Review comment', 'Comment attribut']]\n",
    "df = df.rename(columns={'Review comment': 'text', 'Comment attribut': 'subcategory'})\n",
    "df = df.dropna()\n",
    "df = df.loc[~df['subcategory'].str.contains(',')]\n",
    "df['subcategory'] = df['subcategory'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a402b-621c-4291-bb5f-8d85ff4d77fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_mapper, left_on='subcategory', right_on='Code', how='left')\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "df = df.drop(columns='code', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296de73-cf3a-4fa7-a9ea-7c2dbce3223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceaa648-acfa-4065-a930-f3814508c3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40247b3b-cb95-4365-85ff-1edd75f02a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffda771-72bf-454e-a758-046b64ccf5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.sample(frac=0.8, replace=False, random_state=123)\n",
    "test_df = df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc7a877-9484-48a3-bb35-7cba3f69742d",
   "metadata": {},
   "source": [
    "# Change the level of classification here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb693c1-e052-4f3b-8b33-fbf56f4f0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = 'sentiment'\n",
    "# label = 'category'\n",
    "# label = 'category_2'\n",
    "label = 'curb_attribute'\n",
    "\n",
    "\n",
    "labels = list(train_df[label].unique())\n",
    "\n",
    "fd = f'train_1_label_{label}.jl'\n",
    "train_df[['text', label]].rename(columns={label: 'label'}) \\\n",
    "                         .to_json(fd, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10201f1-950e-4fa8-807b-b01f71b6d949",
   "metadata": {},
   "source": [
    "# Upload training data to endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2212cab-e0ba-4b71-8280-254e1d7e5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "labels = [label.strip().lower().capitalize() for label in labels]\n",
    "labels_tokens = {label: tokenizer.encode(\" \" + label) for label in labels}\n",
    "print(labels_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd3374-2e95-41d6-adf1-99b9403b74b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -ltrh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb8eea-96ad-4278-8e54-0d020bf3fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload = openai.File.create(file=open(fd), purpose=\"classifications\")\n",
    "file_id = upload.id\n",
    "print(file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcbb93b-b238-47d0-be2e-042c38b014f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the file id is logged\n",
    "file_ids = {\n",
    "    'sentiment': 'file-3z9sWq4ZTjifhEH2xmIKmv1g',\n",
    "    'category': 'file-NJuLWvHLfxOTJyd1LJoeWzWQ',\n",
    "    'curb_category': 'file-phtuGFsjXQBxR15PfxIlo9sT'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964d928-e919-486b-a5e9-dbcaf43a6857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# query = 'I would have preferred a little less dressing' \n",
    "\n",
    "result_dict = {}\n",
    "for index, row in test_df.iterrows():\n",
    "    query = row['text']\n",
    "    ground_true = row[label]\n",
    "    try:\n",
    "        result = openai.Classification.create(\n",
    "                                file=file_id,\n",
    "                                query=query,\n",
    "                                search_model=\"ada\",\n",
    "                                model=\"curie\",\n",
    "                                max_examples=200,\n",
    "                                labels=labels,\n",
    "                                logprobs=len(labels)+1,\n",
    "                                expand=[\"completion\"])\n",
    "        result_dict[query] = [result, ground_true]\n",
    "    except:\n",
    "        print(f'Skip: {query}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278aa94-e326-424c-838b-ecafedb3ccbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame.from_dict(result_dict, orient='index')\\\n",
    "                        .reset_index()\\\n",
    "                        .rename(columns={'index': 'text', 0: 'pred_dict', 1: 'ground_true'})\n",
    "\n",
    "result_df['pred'] = [i['label'] for i in result_df.pred_dict]\n",
    "\n",
    "\n",
    "result_df['ground_true'] = result_df['ground_true'].str.lower()\n",
    "result_df['pred'] = result_df['pred'].str.lower()\n",
    "\n",
    "\n",
    "result_df.head()\n",
    "result_df.to_csv(f'results_{label}.csv')\n",
    "\n",
    "\n",
    "labels = [l.lower() for l in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41bb68e-c1d0-499f-a581-b09aa21f0681",
   "metadata": {},
   "source": [
    "# Evaluate the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38415854-84ce-46be-89ac-b5814b2a06ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = 'sentiment'\n",
    "# label = 'category'\n",
    "# label = 'category_2'\n",
    "label = 'curb_attribute'\n",
    "\n",
    "\n",
    "result_df = pd.read_csv(f'./results_{label}.csv')\n",
    "result_df['ground_true'] = result_df['ground_true'].str.lower()\n",
    "result_df['pred'] = result_df['pred'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a88e04-6039-422a-965a-d46f2a0cb87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(result_df.groupby('ground_true', sort=True)['text']\n",
    "           .count()\n",
    "           .reset_index()\n",
    "           .sort_values('text', ascending=False)\n",
    "           .rename(columns={'text': 'counts'})\n",
    "           .reset_index()\n",
    "           .drop('index', axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e488d-a863-48ad-a328-44e30887c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "(result_df.groupby('pred', sort=True)['text']\n",
    "           .count()\n",
    "           .reset_index()\n",
    "           .sort_values('text', ascending=False)\n",
    "           .rename(columns={'text': 'counts'})\n",
    "           .reset_index()\n",
    "           .drop('index', axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebfffb9-ba67-4bf2-b2cc-10e985f00818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapper = pd.read_csv('category.csv')\n",
    "df_mapper['Curb_Attribute'] = df_mapper['Curb_Attribute'].str.lower()\n",
    "df_mapper = df_mapper[['Curb_Attribute', 'Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4899361d-2764-48c1-bca5-f1ceae75fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993306a-2c56-459e-9b5e-1d2cc2cf9c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = (result_df.merge(df_mapper, left_on='ground_true', right_on='Curb_Attribute', how='left')\n",
    "                     .drop('Curb_Attribute', axis=1)\n",
    "                     .merge(df_mapper, left_on='pred', right_on='Curb_Attribute', how='left')\n",
    "                     .drop('Curb_Attribute', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9914866-1adc-4314-84e8-4560c5d41f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c09a2-57e3-4714-b4fc-e3f50013dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b69ec-7ef0-4c98-bfbd-aaf3451d67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve, classification_report\n",
    "\n",
    "report = classification_report(result_df.Category_x, result_df.Category_y)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a68eba-15b1-4530-b739-478a72ebaed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve, classification_report\n",
    "\n",
    "report = classification_report(result_df.ground_true, result_df.pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3b1178-ee60-4e84-87ea-f3bb29991012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "                            confusion_matrix,\n",
    "                            ConfusionMatrixDisplay,\n",
    "                            accuracy_score,\n",
    "                            top_k_accuracy_score,\n",
    "                            balanced_accuracy_score,\n",
    "                            )\n",
    "\n",
    "\n",
    "acc = accuracy_score(result_df.ground_true, result_df.pred)\n",
    "balanced_acc = balanced_accuracy_score(result_df.ground_true, result_df.pred)\n",
    "# top_3_acc = top_k_accuracy_score(result_df.ground_true, result_df.pred, k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de25a0f-069f-4def-a775-3bfec0d15295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c9e149-f849-4696-bc06-f83f93fb7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = set(result_df.ground_true.unique()) | set(result_df.pred.unique())\n",
    "labels = list(labels)\n",
    "\n",
    "cm = confusion_matrix(result_df.ground_true, result_df.pred, labels=labels, normalize='all')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=labels,\n",
    "                              )\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b443b-1067-4690-bec5-c2af5c508c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c111a68-74d9-4809-8920-acdf39f875b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Take the starting tokens for probabilities estimation.\n",
    "# Labels should have distinct starting tokens.\n",
    "# Here tokens are case-insensitive.\n",
    "first_token_to_label = {\n",
    "    tokenizer.decode([tokens[0]]).strip().lower(): label \n",
    "    for label, tokens in labels_tokens.items()\n",
    "}\n",
    "\n",
    "top_logprobs = result[\"completion\"][\"choices\"][0][\"logprobs\"][\"top_logprobs\"][0]\n",
    "token_probs = defaultdict(float)\n",
    "for token, logp in top_logprobs.items():\n",
    "    token_probs[token.strip().lower()] += np.exp(logp)\n",
    "\n",
    "label_probs = {\n",
    "    first_token_to_label[token]: prob \n",
    "    for token, prob in token_probs.items()\n",
    "    if token in first_token_to_label\n",
    "}\n",
    "\n",
    "# Fill in the probability for the special \"Unknown\" label.\n",
    "if sum(label_probs.values()) < 1.0:\n",
    "    label_probs[\"Unknown\"] = 1.0 - sum(label_probs.values())\n",
    "\n",
    "print(label_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
